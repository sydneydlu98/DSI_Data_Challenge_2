---
title: "DSI_Data_Challenge"
author: "Dingxin Lu"
date: "10/10/2021"
output:
  html_document:
    toc: true
    toc_float: true
---
[my github link] https://github.com/sydneydlu98/DSI_Data_Challenge_2

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

*Set up* 
```{r, message=FALSE}
# load all the packages
library(here)
library(readxl)
library(dplyr)
library(tidyverse)
library(janitor)
library(lubridate) 
library(tidyr)
library(stringr)
library(readr)
library(hrbrthemes)
```

## Problem 1

We will be working with data from Mr. Trash Wheel, a water wheel trash collection device that removed trash from the Inner Harbor in Baltimore, Maryland. There are three trash wheels we will be exploring (Mr. Trash Wheel, Professor Trash Wheel, and Captain Trash Wheel). I have provided you the data for this on Canvas in the Excel spreadsheet titled Trash-Wheel-Collection-Totals-8-6-19.xlsx.

Instructions:

* Read in the data from each of the three trash wheels mentioned above using readxl::read_excel.
* First, start with the data from Mr. Trash Wheel:
  + Use janitor::clean_names to clean the column names of the dataframe.
  + Omit rows that do not include dumpster-specific data.
  + Create a wheel variable identifying that these data come from Mr. Trash Wheel.
  + select away any columns that are not needed.
* Perform the same operations above for the data from Professor Trash Wheel and Captain Trash Wheel.
* Use dplyr::bind_rows to bind the three dataframes together into a dataframe called all_trash_wheels.
* Pivot all_trash_wheels to long format where you now have a variable for trash_type and number of each trash type. Make sure you use the correct variables for this!
* Use stringr::str_replace and stringr::str_to_title to format the column trash_type for plotting.
* Create a new dataframe called all_trash_wheels_totals_June_2018 by:
  + Filtering the data for only June 2018, and
  + Using dplyr::group_by and dplyr::summarise to calculate the total number of each trash item collected by each trash wheel for June 2018.
*  Make a faceted bar plot (by trash type) of the amount of trash (x-axis) collected by each wheel (y-axis). Take care to use what we have learned thus far to make an aesthetically pleasing plot!

```{r, message=FALSE}
## read in the data from each of the three trash wheels sheets
mr_trash_wheel <- read_excel("Data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                             sheet = "Mr. Trash Wheel") 

professor_trash_wheel <- read_excel("Data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                                    sheet = "Professor Trash Wheel")

captain_trash_wheel <- read_excel("Data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                                  sheet = "Captain Trash Wheel")

## create a data wrangling function
data_wrangling <- function(data, name) {
  data %>%
    clean_names() %>% ## clean the column names of the dataframe
    filter(is.na(dumpster) == FALSE) %>% ## omit rows that do not include dumpster-specific data
    select(dumpster:homes_powered) %>%
    mutate(wheel = name) %>% ## create a wheel variable identifying data come from each of the 3 sheets
    select(-dumpster, ## select away any columns that are not needed
           -month, 
           -year, 
           -weight_tons, 
           -volume_cubic_yards, 
           -homes_powered)
}
 
## perform the data wrangling function for the data
mr_trash_wheel_clean <- data_wrangling(mr_trash_wheel, 
                                       "Mr. Trash Wheel")
professor_trash_wheel_clean <- data_wrangling(professor_trash_wheel,
                                              "Professor Trash Wheel")
captain_trash_wheel_clean <- data_wrangling(captain_trash_wheel,
                                            "Captain Trash Wheel")
  
## bind the three data frames together into a new dataframe
all_trash_wheels <- bind_rows(mr_trash_wheel_clean,
                              professor_trash_wheel_clean,
                              captain_trash_wheel_clean)

## pivot to long format 
all_trash_wheels_clean <- all_trash_wheels %>%
  pivot_longer(col = -c(date, wheel),
               names_to = 'trash_type', 
               values_to = 'number')

## format the column trash_type
all_trash_wheels_clean$trash_type <- all_trash_wheels_clean$trash_type %>%
  str_replace("_", " ") %>%
  str_to_title()

## create a new data frame for June 2018
all_trash_wheels_June_2018 <- all_trash_wheels_clean %>%
  filter(year(date) == 2018 & month(date) == 6) %>% ## filtering the data for only June 2018
  group_by(wheel, 
           trash_type) %>%
  summarise(total_amount_trash = sum(number, 
                                     na.rm = TRUE)) ## calculate the total number of each trash item collected by each trash wheel for June 2018

## make a faceted bar plot
all_trash_wheels_June_2018 %>%
  ggplot(aes(x = total_amount_trash,
             y = wheel,
             fill = wheel)) +
  geom_bar(stat = "identity") +
  facet_wrap( ~ trash_type, 
              nrow = 4) +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.y = element_blank(),
        legend.position = "bottom") +
  labs(x ='Amount of trash',
       y ='Trash type',
       fill = "Trash wheel:",
       title ='Amount of each type of trash collected by each wheel')
```

## Problem 2

Next we will be examining data from FiveThirtyEight on the S&P closing prices and the unemployment rate. For this problem, the data is provided on Canvas. You will need snp.csv and unemployment.csv.

Instructions:

* Read both .csv files in using readr::read_csv.
* First, start with the snp data:
  + Convert the date to a date object using lubridate::mdy.
  + Note that dates from 1968 and before get converted to 2068 and above! This is the default behavior of lubridate. Come up with a solution to correct this.
  + Create a year and month variable using lubridate::year and lubridate::month. (You will use these in Problem 3.)
* Next, work on wrangling the unemployment data.
  + Convert the data into long format.
  + Create a date column that takes the month and year and indicates the first day of the month. (Hint: to create this date column, I used paste() and lubridate::mdy).
* Plot both the S&P average and the unemployment rate together on the same plot. I found this link helpful! Take care to use what we have learned thus far to make an aesthetically pleasing plot!

```{r, warning=FALSE, message=FALSE}
## load both data
snp <- read_csv("Data/snp.csv")
unemployment <- read_csv("Data/unemployment.csv")

## data wrangling for the snp data
snp_clean <- snp %>%
  mutate(date = as_date(mdy(date))) %>% ## convert the date to a date object
  mutate(date = if_else(date > "2050-01-01",
                        date %m-% years(100),
                        date)) %>%
  mutate(year = year(date)) %>% ## convert dates from 1968 and before
  mutate(month = month(date, 
                       label=TRUE)) ## create a year and month variable

## data wrangling for the unemployment data
unemployment_clean <- unemployment %>%
  pivot_longer(col = c(Jan:Dec),
               names_to = "Month", 
               values_to = "unemployment_rate") %>% ## convert the data into long format
  mutate(date = mdy(paste(Month, "-01-", Year))) ## create a date column that takes the month and year and indicates the first day of the month

## combine adjusted snp and unemployment data
combined_data <- inner_join(snp_clean, 
                            unemployment_clean, 
                            by = c('date'='date'))

## plot both S&P average and the unemployment rate together on the same plot
coeff <- 200
ggplot(combined_data, 
       aes(x = date)) +
  geom_line(aes(y = unemployment_rate), 
            size = 1, 
            color = "black") + 
  geom_line(aes(y = close / coeff), 
            size = 1, 
            color = "#2ca02c") + 
  scale_y_continuous(
    name = "Unemployment rate (%)",
    sec.axis = sec_axis(trans = ~.*coeff, 
                        name="S&P closing price") ) + ## build a second Y axis
  theme_ipsum() +
  theme_minimal() +
  theme(axis.title.y = element_text(color = "black", 
                                    size=14),
        axis.title.y.right = element_text(color = "#2ca02c", 
                                          size=14)) +
  ggtitle("S&P closing price versus the unemployment rate") +
  theme(plot.title = element_text(lineheight=.8, 
                                  size=18,
                                  hjust = 0.5,
                                  face="bold"))
```

## Problem 3

Next we will examine the direct relationship between the S&P closing prices and the unemployment rate using data from 2000 and onward in a scatterplot.

Instructions:

* Since the unemployment rate is available monthly and the S&P closing prices daily, we need to put these on the same temporal scale.
  + Create a new data frame called snp_average.
  + Use the year and month columns you made in Problem 2 and group_by these columns.
  + Calculate the mean closing price for each month and year pair.
  + Create a date column that takes the month and year and indicates the first day of the month. (Hint: to create this date column, I used paste() and lubridate::mdy).
* Join the unemployment data with snp_average and filter for data after the start of 2020.
* Make a plot of the S&P closing price versus the unemployment rate for these years. Color the plot by year. Take care to use what we have learned thus far to make an aesthetically pleasing plot!

```{r, warning=FALSE, message=FALSE}
## create a new data frame called snp_average
snp_average <- snp_clean %>%
  group_by(year, month) %>% ## group_by year and month columns I made in Problem 2
  summarise(mean_price = mean(close)) %>% ## calculate the mean closing price for each month and year pair
  mutate(date = mdy(paste(month, "-01-", year))) ## create a date column that takes the month and year and indicates the first day of the month

## join the unemployment data with snp_average
data <- inner_join(snp_average, 
                   unemployment_clean,
                   by = c('date'='date'))

## filter the data and only includes after the start of 2000
data_updated <- data %>%
  filter(year >= 2000)

## make a plot of the S&P closing price versus the unemployment rate after the start of 2000
coeff <- 200
ggplot(data_updated, 
       aes(x = date)) +
  geom_line(aes(y = unemployment_rate), 
            size = 1, 
            color = "black") + 
  geom_line(aes(y = mean_price / coeff), 
            size = 1, 
            color = "#2ca02c") + 
  scale_y_continuous(
    name = "Unemployment rate (%)",
    sec.axis = sec_axis(trans = ~.*coeff, 
                        name="S&P closing price")) + ## build a second Y axis
  theme_ipsum() +
  theme_minimal() +
  theme(axis.title.y = element_text(color = "black", 
                                    size=14),
        axis.title.y.right = element_text(color = "#2ca02c", 
                                          size=14)) +
  ggtitle("S&P closing price versus unemployment rate after the start of 2000") +
  theme(plot.title = element_text(lineheight=.8, 
                                  size=15,
                                  hjust = 0.5,
                                  face="bold"))
```

## Problem 4

Write a paragraph (at least 5 sentences) describing what you observed in the plots in Problems 2 & 3.

**Answer:** 

**From problem 2,  I observed the changes in unemployment rate versus S&P closing price from the year 1950 to the year 2015. Before the year 1996, changes in unemployment rate is independent to the changes in S&P closing price, as we cannot observe any correlation between these 2 factors. But, after the year 1996, there is a general trend that when unemployment rate goes up, the S&P closing price goes down and vice versa, which shows a reverse relationship. We can say after the year 1996, there is a negative correlation between unemployment rate and S&P closing price, as in S&P closing price goes up, unemployment rate goes down, and vice verse. However, correlation does not mean causation, we have observed such correlation/trend but cannot determine if there is causation between these 2, as in we do not know if one factor actually cause the other factor to happen**

**From question 3, I observed the changes in unemployment rate versus S&P closing price after the start of 2000. We are able to see the data more in detail from the year 2000 onwards. Again, we obverse the negative correlation between unemployment rate and S&P closing price, as in when unemployment rate goes up, the S&P closing price goes down and vice versa. Especially in 2008, S&P closing price dropped significantly and at the same time, unemployment rate rose rapidly. It makes sense as there was financial crisis in the year of 2008 and it was the exact reflection of the economy at that time. Then after 2010, S&P closing price starts to go up again and at the same time unemployment rate goes down. It can indicate the fact that economy started to recover from 2008 financial crisis, but we can really see the economy suffered from 2008 to 2010.**




